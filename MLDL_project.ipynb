{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14072087133445680968\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6686252073\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8819084240028472863\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:1c:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import device\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f = open(\"KakaoTalkChats.txt\", 'r', encoding='UTF8')\n",
    "lines = f.readlines()\n",
    "# 불러온 대화 내역의 emoji를 제거해주는 부분입니다.\n",
    "# refer from https://stackoverflow.com/a/49146722/330558\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                            u\"\\U00002702-\\U000027B0\"\n",
    "                            u\"\\U0001f926-\\U0001f937\"\n",
    "                            u\"\\U00010000-\\U0010ffff\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "lines = [emoji_pattern.sub(r'', k) for k in lines]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%카카오톡 대화를 읽어들입니다.\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#회원님 이라는 단어를 찾으면 그 앞 문장과 현재 문장을 질문-대답으로 묶어냅니다.\n",
    "data = []\n",
    "for i in range(len(lines)):\n",
    "    if '회원님' in lines[i]:\n",
    "        data.append([lines[i - 1], lines[i]])\n",
    "#묶어낸 대화를 ' : '를 기준으로 잘라줍니다.(이름을 제거하고 대화만 남깁니다)\n",
    "for i in range(len(data)):\n",
    "    text, reply = data[i]\n",
    "    text = text[text.find(\" : \") + 3 :]\n",
    "    reply = reply[reply.find(\" : \") + 3 :]\n",
    "    data[i] = [text, reply]\n",
    "#딥러닝 모델에 들어갈 입력의 크기를 정의해줍니다.\n",
    "TEXT_LEN = 30\n",
    "#string의 길이를 늘리거나 줄여주는 함수입니다. 짧으면 왼쪽에 공백 추가, 길면 자릅니다.\n",
    "def max_text(string, t_len):\n",
    "    if len(string) >= t_len: return string[-TEXT_LEN :]\n",
    "    else: return (' ' * (t_len - len(string))) + string\n",
    "\n",
    "#text-reply 형식의 대화를 recurrent한 데이터로 바꿔줍니다.\n",
    "rawX = []\n",
    "rawY = []\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i][1])):\n",
    "        rawX.append(max_text(data[i][0][j:] + data[i][1][:j], TEXT_LEN))\n",
    "        rawY.append(data[i][1][j])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#글자를 숫자로 바꿔주기 위한 dictionarly를 만들어줍니다.\n",
    "flat_data = np.array(data).reshape(-1)\n",
    "flat_data = ''.join(flat_data)\n",
    "chars = sorted(set(list(flat_data)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#데이터를 숫자로 바꿔줍니다.\n",
    "X_ = []\n",
    "Y_ = []\n",
    "for i in range(len(rawX)):\n",
    "    cache = [char_to_int[s]for s in rawX[i]]\n",
    "    X_.append(cache)\n",
    "    Y_.append([char_to_int[rawY[i]]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#ndarray로 바꿔주고 출력은 one-hot-encoding 해줍니다.\n",
    "X = np.array(X_)\n",
    "X = np.reshape(X, (len(X_), TEXT_LEN, 1))\n",
    "Y = np_utils.to_categorical(Y_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "#서술된 모델을 구성합니다. 이때 checkpoint로 epooch 중간중간의 weight를 저장하여줍니다.\n",
    "with device(\"/GPU:0\"):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(1024, input_shape=(X.shape[1], X.shape[2])))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(Y.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#학습시킵니다.\n",
    "    model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "#저장된 weight를 불러오고, 숫자로 된 데이터를 다시 문자로 바꿔주는 dictionary를 정의합니다.\n",
    "filename = \"weights-improvement-20-3.4044_size1024.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           ㅇㅈ\n",
      "나영 너가 이리 얼주 나 참 사이 있 있 있 있는 방 있는 분고 있는 듯 잘지 않을 것 같아"
     ]
    }
   ],
   "source": [
    "# 입력을 넣고 출력을 관찰합니다.\n",
    "\n",
    "input_text = max_text(\"테스트할 입력을 넣는 부분입니다.\\n\", TEXT_LEN)\n",
    "input_text = [char_to_int[s]for s in input_text]\n",
    "print(\"\".join([int_to_char[value] for value in input_text]), end=\"\")\n",
    "\n",
    "while True:\n",
    "    x = np.reshape(input_text, (1, len(input_text), 1))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    if index == 0 : break\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[v] for v in input_text]\n",
    "    sys.stdout.write(result)\n",
    "    input_text.append(index)\n",
    "    input_text = input_text[1:len(input_text)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "with device(\"/GPU:0\"):\n",
    "    model2 = Sequential()\n",
    "    model2.add(LSTM(500, input_shape=(X.shape[1], X.shape[2])))\n",
    "    model2.add(Dropout(0.1))\n",
    "    model2.add(Dense(Y.shape[1], activation='softmax'))\n",
    "    model2.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "filename = \"weights-improvement-50-3.2271.hdf5\"\n",
    "model2.load_weights(filename)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 :      술 많이 먹은 것 같은데 집은 잘 들어갔어?\n",
      "출력 :응선 그거 제 이는 있 이는 있 부 있는 동 이지 것 같아\n",
      "입력 :      술 많이 먹은 것 같은데 집은 잘 들어갔어?\n",
      "출력 :일선 가능하 수 있는 것 같은"
     ]
    }
   ],
   "source": [
    "coinput = \"테스트할 입력을 여기에 적으세요\\n\"\n",
    "input_text = max_text(coinput, TEXT_LEN)\n",
    "input_text = [char_to_int[s]for s in input_text]\n",
    "print(\"입력 :\",\"\".join([int_to_char[value] for value in input_text]), end=\"\")\n",
    "print(\"출력 :\", end=\"\")\n",
    "while True:\n",
    "    x = np.reshape(input_text, (1, len(input_text), 1))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    if index == 0 : break\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[v] for v in input_text]\n",
    "    sys.stdout.write(result)\n",
    "    input_text.append(index)\n",
    "    input_text = input_text[1:len(input_text)]\n",
    "print(\"\")\n",
    "\n",
    "input_text = max_text(coinput, TEXT_LEN)\n",
    "input_text = [char_to_int[s]for s in input_text]\n",
    "print(\"입력 :\",\"\".join([int_to_char[value] for value in input_text]), end=\"\")\n",
    "print(\"출력 :\", end=\"\")\n",
    "while True:\n",
    "    x = np.reshape(input_text, (1, len(input_text), 1))\n",
    "    prediction = model2.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    if index == 0 : break\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[v] for v in input_text]\n",
    "    sys.stdout.write(result)\n",
    "    input_text.append(index)\n",
    "    input_text = input_text[1:len(input_text)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "machinelearning",
   "language": "python",
   "display_name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}